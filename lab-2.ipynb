{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb083b5a-ba65-4da8-adc2-b45176443d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0737e0-6010-43f6-9c5e-7f39d07382fa",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e34bff-6de8-4800-8473-97e50f523f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'spending', 'time', 'at', 'https', ':', '//www.xy123z.com/']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#URL\n",
    "from nltk import word_tokenize\n",
    "token=word_tokenize(\"I love spending time at https://www.xy123z.com/\")\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24eb2b76-34bf-486a-8340-dadb5852349e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "love\n",
      "spending\n",
      "time\n",
      "at\n",
      "https://www.xy123z.com/\n"
     ]
    }
   ],
   "source": [
    "#using spacy we can counter the problem of url splitting\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "text=\"I love spending time at https://www.xy123z.com/\"\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69f616b3-396f-4bab-86a8-30bde92bd259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs: ['https://www.xy123z.com/']\n"
     ]
    }
   ],
   "source": [
    "urls = re.findall(r'https?://\\S+', text)\n",
    "print(\"URLs:\", urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8212028-0c13-4104-90d4-37326e788b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'email', 'ID', 'is', 'xyz111', '@', 'gmail.com']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identifying Email IDs\n",
    "token=word_tokenize(\"My email ID is xyz111@gmail.com\")\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016adcc9-6dc3-47e5-a5ec-a3df4e7cde1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My\n",
      "email\n",
      "ID\n",
      "is\n",
      "xyz111@gmail.com\n"
     ]
    }
   ],
   "source": [
    "#using spacy we can counter the problem of email splitting\n",
    "text=\"My email ID is xyz111@gmail.com\"\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eafb0b26-b37c-44d4-a668-b10716845ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails: ['xyz111@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', text)\n",
    "print(\"Emails:\", emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cceb9460-f21a-4ffc-bbaa-e2eeee65bdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#', 'Sushant', 'is', 'trending', 'now', 'in', 'the', 'world', '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hashtags extraction\n",
    "text=\"#Sushant is trending now in the world.\"\n",
    "token=word_tokenize(text)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d0c8ffa-cb02-4448-899c-3f879f78f16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Sushant']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hashtags=re.findall(r\"#\\w+\",text)\n",
    "hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6873a347-efc2-4449-975d-6af97c73e271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', 'Ajit', ',', 'please', 'help', 'me']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mentions in text\n",
    "token=word_tokenize(\"@Ajit, please help me\")\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735d2a7e-4ed4-41fa-a14f-a1f17e4c8857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Ajit\n",
      ",\n",
      "please\n",
      "help\n",
      "me\n"
     ]
    }
   ],
   "source": [
    "text=\"@Ajit, please help me\"\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0f472e-cc51-4156-bbeb-02893551d075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@Ajit']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions=re.findall(r\"@\\w+\",text)\n",
    "mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f1a608c-a6de-43ed-bdb9-3a49d37eed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8853147\n",
      "sq\n",
      ".\n",
      "km\n",
      "of\n",
      "area\n",
      "washed\n",
      "away\n",
      "in\n",
      "floods\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#Extracting numbers\n",
    "text=\"8853147 sq. km of area washed away in floods.\"\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94b325bc-4b20-4e55-a5e1-6f789a353936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8853147']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers=[token.text for token in doc if token.like_num]\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c67a0b4-796d-45c1-b7c0-a57a237366f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corona\n",
      "vius\n",
      "killed\n",
      "#\n",
      "24506\n",
      "people\n",
      ".\n",
      "#\n",
      "Corona\n",
      "is\n",
      "un(tolerbable\n",
      ")\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#Punctuations\n",
    "text=\"Corona vius killed #24506 people. #Corona is un(tolerbable).\"\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25b4dbf1-1633-4715-b6e6-709f21a71f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#', '.', '#', ')', '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations=[token.text for token in doc if token.is_punct]\n",
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "155af172-2ff9-4c3a-9763-91be3ea0e074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Valid', 'PAN', ':', 'ABCED3193P', ',', 'Invalid', ':', 'lEcGD012eg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PAN numbers\n",
    "token=word_tokenize(\"Valid PAN: ABCED3193P, Invalid: lEcGD012eg\")\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fdd62b1-2799-4b57-81a9-f6794c6153b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABCED3193P']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"Valid PAN: ABCED3193P, Invalid: lEcGD012eg\"\n",
    "pan_pattern=r\"[A-Z]{5}[0-9]{4}[A-Z]{1}\"\n",
    "valid_pans=re.findall(pan_pattern,text)\n",
    "valid_pans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73561e49-d64a-4627-933b-96ed21af4fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heyy', 'this', 'is', 'a', 'verrrry', 'loong', 'texttt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repetitive Characters\n",
    "token=word_tokenize(\"heyy this is a verrrry loong texttt\")\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11d368a0-f2d7-46ed-b215-b345f2c60ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey this is a very long text\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text=\"heyy this is a verrrry loong texttt\"\n",
    "cleaned_text=re.sub(r'(.)\\1+',r'\\1',text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e51b5a3-e76d-415b-af3d-60ce387e42fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9990001796\n",
      "is\n",
      "a\n",
      "phone\n",
      "number\n",
      "of\n",
      "the\n",
      "PMO\n",
      "office\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#Indian Mobile numbers\n",
    "text=\"9990001796 is a phone number of the PMO office.\"\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57029090-fdec-4d2f-969f-bf2f0f54d50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9990001796']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_nums=[token.text for token in doc if token.like_num and len(token.text) ==10]\n",
    "mobile_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0002d26-4452-4761-be5e-a0e49c71ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajit\n",
      "Doval\n",
      "is\n",
      "the\n",
      "National\n",
      "Security\n",
      "Advisor\n",
      "in\n",
      "India\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#Capital words\n",
    "text = \"Ajit Doval is the National Security Advisor in India.\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "864f9c70-684f-42e5-8f2e-923d8f33f01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ajit', 'Doval', 'National', 'Security', 'Advisor', 'India']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capital_words=[token.text for token in doc if token.is_title]\n",
    "capital_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f33c0-fe56-4daa-a5ee-a18703b49928",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1228c902-cf2d-4e6a-ba5f-cc59152fbdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edit_distance(str1,str2):\n",
    "    m=len(str1)\n",
    "    n=len(str2)\n",
    "\n",
    "    dp=[[0 for x in range(n+1)] for x in range(m+1)] #table of size (m+1) x (n+1)\n",
    "\n",
    "    for i in range(m+1):\n",
    "        dp[i][0]=i  #if str2 empty, remove all ch from str1\n",
    "\n",
    "    for j in range(n+1):\n",
    "        dp[0][j]=j #if str1 empty , insert all ch from str2\n",
    "\n",
    "    for i in range(1,m+1):\n",
    "        for j in range(1,n+1):\n",
    "            if str1[i-1]==str2[j-1]:\n",
    "                dp[i][j]=dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j]=1+min(dp[i][j-1],\n",
    "                               dp[i-1][j],\n",
    "                               dp[i-1][j-1])\n",
    "    edit_distance=dp[m][n]\n",
    "\n",
    "    operations =[]\n",
    "    i,j=m,n\n",
    "\n",
    "    while i>0 and j>0:\n",
    "        if str1[i-1] ==str2[j-1]:\n",
    "            i-=1\n",
    "            j-=1\n",
    "\n",
    "        elif dp[i][j] ==dp[i-1][j-1]+1:\n",
    "            operations.append(f\"Substitute '{str1[i-1]}' with '{str2[j-1]}'\")\n",
    "            i-=1\n",
    "            j-=1\n",
    "\n",
    "        elif dp[i][j]==dp[i-1][j]+1:\n",
    "            operations.append(f\"Delete '{str1[i-1]}'\")\n",
    "            i-=1\n",
    "\n",
    "        elif dp[i][j] == dp[i][j-1] +1:\n",
    "            operations.append(f\"Insert '{str2[j-1]}'\")\n",
    "            j-=1\n",
    "\n",
    "    while i>0:\n",
    "        operations.append(f\"Delete '{str1[i-1]}'\")\n",
    "        i-=1\n",
    "    while j>0:\n",
    "        operations.append(f\"Insert '{str2[j-1]}'\")\n",
    "        j-=1\n",
    "    operations.reverse()\n",
    "\n",
    "    return edit_distance,operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7948cc7-1b14-4b64-ba3e-66afd37da0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String 1   | String 2   | Dist | Operations\n",
      "------------------------------------------------------------\n",
      "kitten     | sitting    | 3    |\n",
      "                             + Substitute 'k' with 's'\n",
      "                             + Substitute 'e' with 'i'\n",
      "                             + Insert 'g'\n",
      "------------------------------------------------------------\n",
      "flaw       | lawn       | 2    |\n",
      "                             + Delete 'f'\n",
      "                             + Insert 'n'\n",
      "------------------------------------------------------------\n",
      "distance   | editing    | 5    |\n",
      "                             + Insert 'e'\n",
      "                             + Delete 's'\n",
      "                             + Substitute 'a' with 'i'\n",
      "                             + Delete 'c'\n",
      "                             + Substitute 'e' with 'g'\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    (\"kitten\", \"sitting\"),\n",
    "    (\"flaw\", \"lawn\"),\n",
    "    (\"distance\", \"editing\")\n",
    "]\n",
    "\n",
    "print(f\"{'String 1':<10} | {'String 2':<10} | {'Dist':<4} | {'Operations'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for s1, s2 in test_cases:\n",
    "    dist, ops = calculate_edit_distance(s1, s2)\n",
    "    print(f\"{s1:<10} | {s2:<10} | {dist:<4} |\")\n",
    "    for op in ops:\n",
    "        print(f\"{'':<28} + {op}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee56f2f7-0094-4239-8e5e-2747b270f356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
